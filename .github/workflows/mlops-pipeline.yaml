# .github/workflows/mlops-pipeline.yml
name: MLOps Pipeline

on:
  push:
    branches: [ main ]
    tags: [ 'v*.*.*' ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.10'
  REGISTRY: docker.io
    
jobs:
  security-and-quality:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install safety bandit pytest pytest-cov flake8 mypy
        
    - name: Security scan - Dependencies
      run: |
        echo "Scanning for known security vulnerabilities..."
        safety check --json --output safety-report.json || true
        
    - name: Security scan - Code analysis
      run: |
        echo "Running Bandit security analysis..."
        bandit -r src/ model_app/ -f json -o bandit-report.json || true
        
    - name: Code quality - Linting
      run: |
        echo "Running flake8 linting..."
        flake8 src/ model_app/ --max-line-length=88 --extend-ignore=E203,W503 || true
        
    - name: Code quality - Type checking
      run: |
        echo "Running mypy type checking..."
        mypy src/ --ignore-missing-imports || true
        
    - name: Unit tests
      run: |
        echo "Running unit tests..."
        python -m pytest tests/ -v --cov=src --cov-report=xml --cov-report=term-missing || true
        
    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          safety-report.json
          bandit-report.json
        
  data-processing:
    needs: security-and-quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Process data
      run: |
        python src/data/run_processing.py --input data/raw/house_data.csv --output data/processed/cleaned_house_data.csv 
        
    - name: Engineer features
      run: |
        python src/features/engineer.py --input data/processed/cleaned_house_data.csv --output data/processed/featured_house_data.csv --preprocessor models/trained/preprocessor.pkl
        
    - name: Validate processed data
      run: |
        if [ ! -f "data/processed/featured_house_data.csv" ]; then
          echo "Error: Featured data not created"
          exit 1
        fi
        if [ ! -s "data/processed/featured_house_data.csv" ]; then
          echo "Error: Featured data file is empty"
          exit 1
        fi
        echo "Data processing validation passed"
        
    - name: Upload processed data
      uses: actions/upload-artifact@v4
      with:
        name: processed-data
        path: data/processed/featured_house_data.csv
        
    - name: Upload preprocessor
      uses: actions/upload-artifact@v4
      with:
        name: preprocessor
        path: models/trained/preprocessor.pkl
        
  model-training:
    needs: data-processing
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Download processed data
      uses: actions/download-artifact@v4
      with:
        name: processed-data
        path: data/processed/
        
    - name: Set up MLflow
      run: |
        docker pull ghcr.io/mlflow/mlflow:latest
        docker run -d -p 5000:5000 --name mlflow-server ghcr.io/mlflow/mlflow:latest mlflow server --host 0.0.0.0 --backend-store-uri sqlite:///mlflow.db
        
    - name: Wait for MLflow to start
      run: |
        echo "Waiting for MLflow to be ready..."
        for i in {1..30}; do
          if curl -f http://localhost:5000/health 2>/dev/null; then
            echo "MLflow is ready!"
            break
          fi
          if [ $i -eq 30 ]; then
            echo "MLflow failed to start after 150 seconds"
            docker logs mlflow-server
            exit 1
          fi
          echo "Attempt $i/30: MLflow not ready, waiting 5 seconds..."
          sleep 5
        done
        
    - name: Validate config file
      run: |
        if [ ! -f "configs/model_config.yaml" ]; then
          echo "Error: Model config file not found"
          exit 1
        fi
        echo "Config file validation passed"
        
    - name: Train model
      run: |
        mkdir -p models
        python src/models/train_model.py --config configs/model_config.yaml --data data/processed/featured_house_data.csv --models-dir models --mlflow-tracking-uri http://localhost:5000
        
    - name: Model performance testing
      run: |
        echo "Running model performance tests..."
        python -c "
        import os
        import pandas as pd
        import numpy as np
        
        # Load test data
        data = pd.read_csv('data/processed/featured_house_data.csv')
        
        # Load model (check if model files exist)
        model_files = [f for f in os.listdir('models') if f.endswith('.pkl')]
        if not model_files:
            print('Error: No model files found')
            exit(1)
        
        # Simple performance validation
        print('Model performance validation passed')
        "
        
    - name: Model drift detection
      run: |
        echo "Checking for data drift..."
        python -c "
        import pandas as pd
        import numpy as np
        
        # Load current data
        current_data = pd.read_csv('data/processed/featured_house_data.csv')
        
        # Basic drift checks (statistical)
        numeric_cols = current_data.select_dtypes(include=[np.number]).columns
        drift_detected = False
        
        for col in numeric_cols:
            if col != 'price':  # Skip target variable
                mean_val = current_data[col].mean()
                std_val = current_data[col].std()
                
                # Simple drift detection: check if mean is reasonable
                if pd.isna(mean_val) or pd.isna(std_val):
                    print(f'Warning: Data quality issue in column {col}')
                    drift_detected = True
        
        if drift_detected:
            print('Warning: Potential data drift detected')
        else:
            print('No significant data drift detected')
        "
        
    - name: Validate trained model
      run: |
        if [ ! -d "models" ] || [ -z "$(ls -A models 2>/dev/null)" ]; then
          echo "Error: No model files were created"
          exit 1
        fi
        echo "Model training validation passed"
        
    - name: Upload trained model
      uses: actions/upload-artifact@v4
      with:
        name: trained-model
        path: models/
        
    - name: Clean up MLflow
      run: |
        docker stop mlflow-server || true
        docker rm mlflow-server || true
        
  build-and-publish:
    needs: model-training
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download trained model
      uses: actions/download-artifact@v4
      with:
        name: trained-model
        path: models/
        
    - name: Download preprocessor
      uses: actions/download-artifact@v4
      with:
        name: preprocessor
        path: models/trained/
        
    - name: Validate artifacts
      run: |
        if [ ! -d "models" ] || [ -z "$(ls -A models 2>/dev/null)" ]; then
          echo "Error: No trained model artifacts found"
          exit 1
        fi
        if [ ! -f "models/trained/preprocessor.pkl" ]; then
          echo "Error: Preprocessor not found"
          exit 1
        fi
        echo "Artifact validation passed"
        
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      

    - name: Log in to DockerHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: docker.io
        username: ${{ vars.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}


    - name: Generate version tags
      id: meta
      run: |
        if [[ "${{ github.ref_type }}" == "tag" ]]; then
          # For tag pushes, use the tag name
          VERSION="${{ github.ref_name }}"
          echo "tags=${{ env.REGISTRY }}/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:${VERSION},${{ env.REGISTRY }}/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest" >> $GITHUB_OUTPUT
        else
          # For branch pushes, use branch name and commit SHA
          BRANCH_NAME=$(echo "${{ github.ref_name }}" | tr '/' '-')
          SHORT_SHA=$(echo "${{ github.sha }}" | cut -c1-8)
          echo "tags=${{ env.REGISTRY }}/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:${BRANCH_NAME}-${SHORT_SHA},${{ env.REGISTRY }}/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest" >> $GITHUB_OUTPUT
        fi
        
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
          context: ./model_app
          file: ./model_app/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          platforms: linux/amd64,linux/arm64
          cache-from: type=gha
          cache-to: type=gha,mode=max
          
    - name: Run container security scan
      uses: anchore/scan-action@v3
      with:
        image: ${{ env.REGISTRY }}/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest
        fail-build: false
        
    - name: Upload container scan results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: container-scan-results
        path: |
          anchore-reports/
          
    - name: Integration test
      run: |
        echo "Starting integration tests..."
        # Pull the built image
        docker pull ${{ env.REGISTRY }}/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest
        
        # Start the container
        docker run -d --name test-api -p 8000:8000 ${{ env.REGISTRY }}/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest
        
        # Wait for container to be ready
        sleep 10
        
        # Test health endpoint
        curl -f http://localhost:8000/health || exit 1
        
        # Test prediction endpoint
        curl -f -X POST http://localhost:8000/predict \
          -H "Content-Type: application/json" \
          -d '{"sqft": 1500, "bedrooms": 3, "bathrooms": 2, "location": "suburban", "year_built": 2000, "condition": "Fair"}' || exit 1
          
        echo "Integration tests passed!"
        
        # Cleanup
        docker stop test-api
        docker rm test-api
